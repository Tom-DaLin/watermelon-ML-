{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 10)\n",
      "(569,)\n",
      "(455, 10)\n",
      "(114, 10)\n",
      "(455,)\n",
      "(114,)\n"
     ]
    }
   ],
   "source": [
    "#乳腺癌分类数据集（二分类问题）\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "data = cancer.data[:, :10]\n",
    "target = cancer.target\n",
    "\n",
    "print(data.shape)\n",
    "print(target.shape)\n",
    "\n",
    "#标准化 若不标准化，则x值太大，在计算p1_xb时对初始值过于敏感，求dldl_dbetadbeta逆时，出现奇异矩阵，无法计算\n",
    "#牛顿法其实限制很多 不稳定\n",
    "ss = MinMaxScaler()\n",
    "data = ss.fit_transform(data)\n",
    "\n",
    "#拆分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2)\n",
    "\n",
    "#展示数据维度\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self):\n",
    "        self.beta = None\n",
    "        \n",
    "    def fit(self, x, y, n_iters=100):\n",
    "        n_examples = x.shape[0]\n",
    "\n",
    "        extra = np.ones(n_examples)\n",
    "        X = np.c_[x, extra]\n",
    "        \n",
    "        #西瓜书中采用牛顿法求解\n",
    "        self.beta = np.random.random((X.shape[1],))\n",
    "\n",
    "        #牛顿法迭代求解\n",
    "        for n in range(n_iters):\n",
    "            dl_dbeta = np.zeros(X.shape[1]) \n",
    "            dldl_dbetadbeta = np.zeros((X.shape[1], X.shape[1])) #hessian矩阵\n",
    "            for i in range(n_examples):    #求和\n",
    "                \n",
    "                #防止exp溢出\n",
    "                a = X[i].dot(self.beta) \n",
    "                if a>=0:\n",
    "                    p1_xb = 1 / (1 + np.exp(-a))\n",
    "                else:\n",
    "                    p1_xb = np.exp(a) / (1 + np.exp(a))\n",
    "\n",
    "                dl_dbeta += X[i]*(y_train[i] - p1_xb)                        #公式3.30\n",
    "                \n",
    "                tmp = X[i].reshape(-1,1)  \n",
    "                dldl_dbetadbeta += tmp.dot(tmp.T)*p1_xb*(1-p1_xb)  #公式3.31\n",
    "\n",
    "            try:\n",
    "                self.beta -=  np.linalg.inv(dldl_dbetadbeta).dot(-dl_dbeta) #公式3.29\n",
    "            except:      #通常当黑塞矩阵奇异的时候，说明梯度已经非常小了，也可以认为此时已经收敛了\n",
    "                self.beta = self.beta\n",
    "    \n",
    "    def predict(self, x):\n",
    "        n_examples = x.shape[0]\n",
    "\n",
    "        extra = np.ones(n_examples)\n",
    "        X = np.c_[x, extra]\n",
    "        \n",
    "        y1_proba = [] #记录是1的概率\n",
    "        for i in range(n_examples):\n",
    "            a = X[i].dot(self.beta)\n",
    "            if a>=0:\n",
    "                p1_xb = 1 / (1 + np.exp(-a))\n",
    "            else:\n",
    "                p1_xb = np.exp(a) / (1 + np.exp(a))\n",
    "            y1_proba.append(p1_xb)\n",
    "\n",
    "        y1_hat = [1 if i>0.5 else 0 for i in y1_proba] #概率转类别\n",
    "        return np.array(y1_hat)\n",
    "        \n",
    "        \n",
    "def accuracy_score(y, y_hat):\n",
    "    return len(np.where(y==y_hat)[0]) / len(y)        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numpy\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train, n_iters=100)\n",
    "y_hat = lr.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "#sklearn\n",
    "from sklearn import linear_model\n",
    "lr = linear_model.LogisticRegression(max_iter=100,solver='newton-cg')\n",
    "lr.fit(x_train, y_train)\n",
    "y_hat = lr.predict(x_test)\n",
    "print(accuracy_score(y_test, y_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
